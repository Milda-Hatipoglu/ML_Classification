{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting 10-Year Coronary Heart Disease (CHD) Risk**\n",
    "\n",
    "Cardiovascular diseases are the `leading` global `cause of death`, with `coronary heart disease` (CHD) being the most prevalent. According to the [World Health Organization (WHO)](https://www.who.int/data/gho/data/themes/mortality-and-global-health-estimates/ghe-leading-causes-of-death), CHD accounted for 13% of global deaths from 2000 to 2021. In the U.S., the [National Heart, Lung, and Blood Institute (NHLBI)](https://www.nhlbi.nih.gov/health/coronary-heart-disease/risk-factors) states that nearly half of adults have at least one major CHD risk factor: high blood pressure, high cholesterol, or smoking.  \n",
    "\n",
    "This project aims to build a `logistic regression model` to estimate an individual’s `10-year CHD probability`. The focus is on balancing predictive accuracy, interpretability, and classification effectiveness to support risk assessment. The [Kaggle dataset](https://www.kaggle.com/datasets/christofel04/cardiovascular-study-dataset-predict-heart-disea), which is relied upon in this project, is reportedly linked to the [Framingham Heart Study](https://www.framinghamheartstudy.org/fhs-about/), a cornerstone in cardiovascular research. \n",
    "\n",
    "However, the dataset lacks transparency regarding its true origin, as `no metadata` was found on Kaggle. Key details such as data collection timeframe, participant selection criteria, geographic representation, other possible predictors or preprocessing methods remain unknown. Without this information, the dataset’s reliability and generalizability cannot be fully assessed. Therefore, findings should be interpreted with caution.\n",
    "\n",
    "##### **Project Roadmap**\n",
    "\n",
    "| Stage | Objective |\n",
    "|-----------|--------------|\n",
    "| 1. Data Cleaning | Handle missing values, encode categorical variables, and standardize numerical features for consistency. |\n",
    "| 2. Exploratory Data Analysis (EDA) | Examine feature distributions, assess correlations, and identify multicollinearity. |\n",
    "| 3. Modeling | Train a logistic regression model, perform feature selection, optimize classification thresholds, and validate performance. |\n",
    "| 4. Interpretation and Considerations | Analyze model coefficients, assess predictive significance, evaluate generalizability, and discuss dataset limitations. |\n",
    "\n",
    "<br>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Data Cleaning**  \n",
    "\n",
    "This section deals with loading and describing the dataset, examining it for missing values, inconsistencies, and potential issues such as duplicate records or incorrect data types. Categorical variables are encoded, and numerical features are standardized. Additionally, outliers are identified and handled to prevent extreme values from distorting model performance.\n",
    "\n",
    "##### **1.1. Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     accuracy_score, precision_score, recall_score, f1_score, \n\u001b[0;32m     14\u001b[0m     roc_auc_score, roc_curve, confusion_matrix, classification_report, \n\u001b[0;32m     15\u001b[0m     precision_recall_curve\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logit, add_constant\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutliers_influence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variance_inflation_factor\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report, \n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "from statsmodels.api import Logit, add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.5f}\".format)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M4S4_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
